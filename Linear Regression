import numpy as np
from sklearn import datasets, linear_model, metrics


## Load the diabetes dataset
diabetes = datasets.load_diabetes()
diabetes_X = diabetes.data # matrix of dimensions 442x10
 
# Split the data into training/testing sets
diabetes_X_train = diabetes_X[:-20]
diabetes_X_test = diabetes_X[-20:]
 
# Split the targets into training/testing sets
diabetes_y_train = diabetes.target[:-20]
diabetes_y_test = diabetes.target[-20:]

# train
X = diabetes_X_train
y = diabetes_y_train
y = (np.reshape(y,(1, y.size))).T
X=np.concatenate((np.ones((len(X),1)),X),axis=1)
# train: init
W = np.random.randn(11,1)

learning_rate =0.0001
epochs = 100
 
# train: gradient descent
for i in range(epochs):
    # calculate predictions
    predictions=X@W
 
    # calculate error and cost (mean squared error)
    m=len(X)
    mean_squared_error=(1/2*m)*(np.sum(np.square(y-predictions)))
 
    # calculate gradients
    grad=(X.T)@(y-predictions)
 
    # update parameters
    W=W-(learning_rate*(1/m)*grad)
 
    # diagnostic output
    if i % 5000 == 0: print("Epoch %d: %f" % (i, mean_squared_error))
    
    
X = diabetes_X_test
y = diabetes_y_test
y = (np.reshape(y,(1, y.size))).T
X=np.concatenate((np.ones((len(X),1)),X),axis=1)


    # calculate predictions
predictions=np.dot(X,W)

    # calculate error and cost (mean squared error)
m=len(X)
mean_squared_error=(1/2*m)*(np.sum(np.square(y-predictions)))
 
print('Coefficients: \n', W)
print("Mean squared error: %.2f" % mean_squared_error)
print("="*120)
